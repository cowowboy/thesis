{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110415 min 248457 max\n",
      "(110415, 8)\n",
      "(138042,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pick out \n",
    "def Data_compare(data,window):\n",
    "    view_count = 0\n",
    "    request_num = 0\n",
    "    start_time = -1\n",
    "    timestamp = 0\n",
    "    end_time = 0\n",
    "    idx = []\n",
    "    for i in range(data.shape[0]):\n",
    "        timestamp = int(str(data.iloc[i,0])[3:10])\n",
    "        if start_time == -1:\n",
    "            start_time = timestamp + (window-1) * 86400\n",
    "            end_time = start_time + window * 86400\n",
    "        if end_time < timestamp:\n",
    "            break\n",
    "        if (timestamp >= start_time and timestamp <= end_time):\n",
    "            idx.append(i)\n",
    "    print(idx[0],'min',idx[-1],'max')\n",
    "    return idx\n",
    "\n",
    "data = pd.read_csv(\"./test_20180920 _orgin\")\n",
    "data[\"Video_ID\"] = pd.Categorical(data['Video_ID'], categories=data[\"Video_ID\"].unique()).codes\n",
    "idx = Data_compare(data,7)\n",
    "\n",
    "train_data = data.iloc[:idx[0]]\n",
    "test_data = data.iloc[idx[0]:idx[-1],1]\n",
    "test_data.to_csv(\"./testing_1001_video.csv\",index=0)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete repeated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57353, 8)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.drop_duplicates(subset=['Video_ID'], keep=\"first\")\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete view_count == 0  rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data[train_data.Video_Count != 0]\n",
    "train_data[\"Video_ID\"].to_csv(\"./training_1001_video.csv\",index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Req_time  Video_ID  Video_Category  Video_Count  Like_Count  \\\n",
      "33543   1.201806e+09     20714               1   1002205775     1487329   \n",
      "55      1.201640e+09        48              23    850764845     1657651   \n",
      "6633    1.201663e+09      4687              10    534786167     2751681   \n",
      "6634    1.201663e+09      4688              23    299358415     1203195   \n",
      "38555   1.201822e+09     23501              10    290252671      527616   \n",
      "3359    1.201653e+09      2527              26    279060475        2977   \n",
      "5545    1.201660e+09      3982              10    260780126     1079685   \n",
      "65      1.201640e+09        58              10    215102526     1069962   \n",
      "4895    1.201658e+09      3551              10    204147380      407396   \n",
      "10770   1.201679e+09      7221              10    201162163      858872   \n",
      "84013   1.202019e+09     45826              10    190476499     1231718   \n",
      "4049    1.201655e+09      3003              10    175273975      385168   \n",
      "6653    1.201663e+09      4701              23    174616391     1034878   \n",
      "34775   1.201811e+09     21419              15    170890159       38907   \n",
      "89821   1.202068e+09     48457              24    166314026       75796   \n",
      "24476   1.201749e+09     15573              10    163069564      374957   \n",
      "197     1.201641e+09       160              24    153580993      245147   \n",
      "4121    1.201655e+09      3053              10    133979414      576853   \n",
      "41161   1.201830e+09     24919              10    133412073      575138   \n",
      "34090   1.201808e+09     21036              24    131213279       14562   \n",
      "17661   1.201728e+09     11523              10    130186348      177884   \n",
      "18851   1.201732e+09     12212              10    126768940      442896   \n",
      "18527   1.201731e+09     12019              10    115912146      365231   \n",
      "17956   1.201729e+09     11706              23    113997095      278249   \n",
      "21388   1.201741e+09     13783              10    113876718      456901   \n",
      "3920    1.201655e+09      2906              10    113643712      836131   \n",
      "19020   1.201733e+09     12322              24    112401269       15943   \n",
      "11789   1.201703e+09      7795              10    111450809        7129   \n",
      "12249   1.201707e+09      8096              10    109752211      759100   \n",
      "22386   1.201744e+09     14405              10    109440090      760362   \n",
      "...              ...       ...             ...          ...         ...   \n",
      "33418   1.201806e+09     20633              19           42           0   \n",
      "74955   1.201991e+09     41552               1           42           1   \n",
      "56585   1.201901e+09     32618              22           39           0   \n",
      "103810  1.202134e+09     54555              22           38           1   \n",
      "45746   1.201842e+09     27219              17           37           0   \n",
      "20457   1.201738e+09     13191               1           37           0   \n",
      "89797   1.202068e+09     48443              23           36           0   \n",
      "38914   1.201823e+09     23725              24           35           0   \n",
      "24949   1.201750e+09     15813              24           34           0   \n",
      "60304   1.201913e+09     34382              23           33           0   \n",
      "33347   1.201806e+09     20595              19           33           0   \n",
      "33211   1.201805e+09     20509              19           32           0   \n",
      "12161   1.201706e+09      8038              22           32           0   \n",
      "55231   1.201899e+09     31997              24           30           0   \n",
      "10127   1.201674e+09      6878              22           30           0   \n",
      "33361   1.201806e+09     20606              19           28           0   \n",
      "8020    1.201666e+09      5508              10           28           0   \n",
      "49789   1.201880e+09     29241              15           26           0   \n",
      "97745   1.202095e+09     51999              15           25           1   \n",
      "54928   1.201898e+09     31842              23           24           0   \n",
      "102408  1.202110e+09     53881              28           23           0   \n",
      "24575   1.201749e+09     15609              28           22           0   \n",
      "36056   1.201814e+09     22144              27           19           0   \n",
      "48507   1.201859e+09     28654              26           17           0   \n",
      "103323  1.202128e+09     54364               1           16           0   \n",
      "33430   1.201806e+09     20641              19           11           0   \n",
      "33428   1.201806e+09     20640              19            6           0   \n",
      "11987   1.201705e+09      7931              10            0           0   \n",
      "75736   1.201993e+09     41927              23            0        1407   \n",
      "109768  1.202156e+09     57050              24            0         174   \n",
      "\n",
      "        Dislike_Count  Comment_Count  Local_View  \n",
      "33543          437007         176832           1  \n",
      "55             237484         364710           1  \n",
      "6633            59412         177743           1  \n",
      "6634            94177         232861           1  \n",
      "38555           28886          28080           1  \n",
      "3359             1820           2965           1  \n",
      "5545            24744          88434           1  \n",
      "65              28234          51600           1  \n",
      "4895            23052          51409           1  \n",
      "10770           22698          36293           1  \n",
      "84013           30739         140936           1  \n",
      "4049            37381          51469           1  \n",
      "6653            35117         125474           1  \n",
      "34775           21593           3938           1  \n",
      "89821          237576           1659           1  \n",
      "24476           11443          54492           1  \n",
      "197             15346              0           1  \n",
      "4121            14176          61263           1  \n",
      "41161            9242          27938           1  \n",
      "34090            7978           2835           1  \n",
      "17661           16385          28446           1  \n",
      "18851           14965          37451           1  \n",
      "18527            8474          42417           1  \n",
      "17956           17320          43088           1  \n",
      "21388           10231          26041           1  \n",
      "3920           107321         310663           1  \n",
      "19020           29354           4798           1  \n",
      "11789            5382           1070           1  \n",
      "12249           13644          41200           1  \n",
      "22386           12296          80870           1  \n",
      "...               ...            ...         ...  \n",
      "33418               0              0           1  \n",
      "74955               0              0           1  \n",
      "56585               0              0           1  \n",
      "103810              0              0           1  \n",
      "45746               0              0           1  \n",
      "20457               0              0           1  \n",
      "89797               0              0           1  \n",
      "38914               0              0           1  \n",
      "24949               0              1           1  \n",
      "60304               0              0           1  \n",
      "33347               0              0           1  \n",
      "33211               0              0           1  \n",
      "12161               0              0           1  \n",
      "55231               0              0           1  \n",
      "10127               0              1           1  \n",
      "33361               0              0           1  \n",
      "8020                0              0           1  \n",
      "49789               0              0           1  \n",
      "97745               0              0           1  \n",
      "54928               0              0           1  \n",
      "102408              0              0           1  \n",
      "24575               0              0           1  \n",
      "36056               0              0           1  \n",
      "48507               0              0           1  \n",
      "103323              0              0           1  \n",
      "33430               0              0           1  \n",
      "33428               0              0           1  \n",
      "11987               0              0           1  \n",
      "75736              83            292           1  \n",
      "109768             21             46           1  \n",
      "\n",
      "[57353 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmnet\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.sort(['Video_Count'],ascending=False)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize Labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33543     4\n",
      "55        4\n",
      "6633      4\n",
      "6634      4\n",
      "38555     4\n",
      "3359      4\n",
      "5545      4\n",
      "65        4\n",
      "4895      4\n",
      "10770     4\n",
      "84013     4\n",
      "4049      4\n",
      "6653      4\n",
      "34775     4\n",
      "89821     4\n",
      "24476     4\n",
      "197       4\n",
      "4121      4\n",
      "41161     4\n",
      "34090     4\n",
      "17661     4\n",
      "18851     4\n",
      "18527     4\n",
      "17956     4\n",
      "21388     4\n",
      "3920      4\n",
      "19020     4\n",
      "11789     4\n",
      "12249     4\n",
      "22386     4\n",
      "         ..\n",
      "29926     0\n",
      "33305     0\n",
      "33365     0\n",
      "74955     0\n",
      "33418     0\n",
      "56585     0\n",
      "103810    0\n",
      "45746     0\n",
      "20457     0\n",
      "89797     0\n",
      "38914     0\n",
      "24949     0\n",
      "60304     0\n",
      "33347     0\n",
      "12161     0\n",
      "33211     0\n",
      "10127     0\n",
      "55231     0\n",
      "8020      0\n",
      "33361     0\n",
      "49789     0\n",
      "97745     0\n",
      "54928     0\n",
      "102408    0\n",
      "24575     0\n",
      "36056     0\n",
      "48507     0\n",
      "103323    0\n",
      "33430     0\n",
      "33428     0\n",
      "Name: labels, dtype: category\n",
      "Categories (5, int64): [0 < 1 < 2 < 3 < 4]\n"
     ]
    }
   ],
   "source": [
    "#labels = ['0','class2','class3','class4','popular']\n",
    "labels = [0,1,2,3,4]\n",
    "train_data['labels'] = pd.qcut(train_data.Video_Count, 5, labels=labels)\n",
    "print(train_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57350, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.sort_index(axis=0)\n",
    "train_data.to_csv(\"./training_1001_labeled.csv\",index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Very Fast Decision Tree i.e. Hoeffding Tree, described in\n",
    "# \"Mining High-Speed Data Streams\" (Domingos & Hulten, 2000)\n",
    "#\n",
    "# this program contains 2 classes: Vfdt, VfdtNode\n",
    "# test in command line window: python3 Vfdt.py\n",
    "# changed to CART: gini index\n",
    "#\n",
    "# Jamie\n",
    "# 02/06/2018\n",
    "# ver 0.03\n",
    "\n",
    "import time\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# VFDT node class\n",
    "class VfdtNode:\n",
    "    def __init__(self, possible_split_features):\n",
    "        \"\"\"\n",
    "        nijk: statistics of feature i, value j, class\n",
    "        :list possible_split_features: features\n",
    "        \"\"\"\n",
    "        self.parent = None\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.split_feature = None\n",
    "        self.split_value = None  # both continuous and discrete value\n",
    "        self.new_examples_seen = 0\n",
    "        self.total_examples_seen = 0\n",
    "        self.class_frequency = {}\n",
    "        self.nijk = {f: {} for f in possible_split_features}\n",
    "        self.possible_split_features = possible_split_features\n",
    "\n",
    "    def add_children(self, split_feature, split_value, left, right):\n",
    "        self.split_feature = split_feature\n",
    "        self.split_value = split_value\n",
    "        self.left_child = left\n",
    "        self.right_child = right\n",
    "        left.parent = self\n",
    "        right.parent = self\n",
    "\n",
    "        self.nijk.clear()  # reset stats\n",
    "        if isinstance(split_value, list):\n",
    "            left_value = split_value[0]\n",
    "            right_value = split_value[1]\n",
    "            # discrete split value list's length = 1, stop splitting\n",
    "            if len(left_value) <= 1:\n",
    "                new_features = [None if f == split_feature else f for f in left.possible_split_features]\n",
    "                left.possible_split_features = new_features\n",
    "            if len(right_value) <= 1:\n",
    "                new_features = [None if f == split_feature else f for f in right.possible_split_features]\n",
    "                right.possible_split_features = new_features\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.left_child is None and self.right_child is None\n",
    "\n",
    "    # recursively trace down the tree to distribute data examples to corresponding leaves\n",
    "    def sort_example(self, x):\n",
    "        if self.is_leaf():\n",
    "            return self\n",
    "        else:\n",
    "            index = self.possible_split_features.index(self.split_feature)\n",
    "            value = x[index]\n",
    "            split_value = self.split_value\n",
    "\n",
    "            if isinstance(split_value, list):  # discrete value\n",
    "                if value in split_value[0]:\n",
    "                    return self.left_child.sort_example(x)\n",
    "                else:\n",
    "                    return self.right_child.sort_example(x)\n",
    "            else:  # continuous value\n",
    "                if value <= split_value:\n",
    "                    return self.left_child.sort_example(x)\n",
    "                else:\n",
    "                    return self.right_child.sort_example(x)\n",
    "\n",
    "    # the most frequent class\n",
    "    def most_frequent(self):\n",
    "        try:\n",
    "            prediction = max(self.class_frequency, key=self.class_frequency.get)\n",
    "        except ValueError:\n",
    "            # if self.class_frequency dict is empty, go back to parent\n",
    "            class_frequency = self.parent.class_frequency\n",
    "            prediction = max(class_frequency, key=class_frequency.get)\n",
    "        return prediction\n",
    "\n",
    "    # update leaf stats in order to calculate infomation gain\n",
    "    def update_stats(self, x, y):\n",
    "        feats = self.possible_split_features\n",
    "        nijk = self.nijk\n",
    "        iterator = [f for f in feats if f is not None]\n",
    "        for i in iterator:\n",
    "            value = x[feats.index(i)]\n",
    "            if value not in nijk[i]:\n",
    "                nijk[i][value] = {y: 1}\n",
    "            else:\n",
    "                try:\n",
    "                    nijk[i][value][y] += 1\n",
    "                except KeyError:\n",
    "                    nijk[i][value][y] = 1\n",
    "\n",
    "        self.total_examples_seen += 1\n",
    "        self.new_examples_seen += 1\n",
    "        class_frequency = self.class_frequency\n",
    "        try:\n",
    "            class_frequency[y] += 1\n",
    "        except KeyError:\n",
    "            class_frequency[y] = 1\n",
    "\n",
    "    def check_not_splitting(self):\n",
    "        # compute gini index for not splitting\n",
    "        X0 = 1\n",
    "        class_frequency = self.class_frequency\n",
    "        n = sum(class_frequency.values())\n",
    "        for j, k in class_frequency.items():\n",
    "            X0 -= (k/n)**2\n",
    "        return X0\n",
    "\n",
    "    # use Hoeffding tree model to test node split, return the split feature\n",
    "    def attempt_split(self, delta, nmin, tau):\n",
    "        if self.new_examples_seen < nmin:\n",
    "            return None\n",
    "        class_frequency = self.class_frequency\n",
    "        if len(class_frequency) == 1:\n",
    "            return None\n",
    "\n",
    "        self.new_examples_seen = 0  # reset\n",
    "        nijk = self.nijk\n",
    "        min = 1\n",
    "        second_min = 1\n",
    "        Xa = ''\n",
    "        split_value = None\n",
    "        for feature in self.possible_split_features:\n",
    "            if feature is not None:\n",
    "                njk = nijk[feature]\n",
    "                gini, value = self.gini(njk, class_frequency)\n",
    "                if gini < min:\n",
    "                    min = gini\n",
    "                    Xa = feature\n",
    "                    split_value = value\n",
    "                elif min < gini < second_min:\n",
    "                    second_min = gini\n",
    "\n",
    "        epsilon = self.hoeffding_bound(delta)\n",
    "        g_X0 = self.check_not_splitting()\n",
    "        if min < g_X0:\n",
    "            # print(second_min - min, epsilon)\n",
    "            if second_min - min > epsilon:\n",
    "                # print('1 node split')\n",
    "                return [Xa, split_value]\n",
    "            elif second_min - min < epsilon < tau:\n",
    "                # print('2 node split')\n",
    "                return [Xa, split_value]\n",
    "            else:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "    def hoeffding_bound(self, delta):\n",
    "        n = self.total_examples_seen\n",
    "        R = np.log(len(self.class_frequency))\n",
    "        return np.sqrt(R * R * np.log(1/delta) / (2 * n))\n",
    "\n",
    "    def gini(self, njk, class_frequency):\n",
    "        # gini(D) = 1 - Sum(pi^2)\n",
    "        # gini(D, F=f) = |D1|/|D|*gini(D1) + |D2|/|D|*gini(D2)\n",
    "\n",
    "        D = self.total_examples_seen\n",
    "        m1 = 1  # minimum gini\n",
    "        # m2 = 1  # second minimum gini\n",
    "        Xa_value = None\n",
    "        feature_values = list(njk.keys())  # list() is essential\n",
    "        if not isinstance(feature_values[0], str):  # numeric  feature values\n",
    "            sort = np.array(sorted(feature_values))\n",
    "            split = (sort[0:-1] + sort[1:])/2   # vectorized computation, like in R\n",
    "\n",
    "            D1_class_frequency = {j: 0 for j in class_frequency.keys()}\n",
    "            for index in range(len(split)):\n",
    "                nk = njk[sort[index]]\n",
    "                for j in nk:\n",
    "                    D1_class_frequency[j] += nk[j]\n",
    "                D1 = sum(D1_class_frequency.values())\n",
    "                D2 = D - D1\n",
    "                g_d1 = 1\n",
    "                g_d2 = 1\n",
    "\n",
    "                D2_class_frequency = {}\n",
    "                for key, value in class_frequency.items():\n",
    "                    if key in D1_class_frequency:\n",
    "                        D2_class_frequency[key] = value - D1_class_frequency[key]\n",
    "                    else:\n",
    "                        D2_class_frequency[key] = value\n",
    "\n",
    "                for key, v in D1_class_frequency.items():\n",
    "                    g_d1 -= (v/D1)**2\n",
    "                for key, v in D2_class_frequency.items():\n",
    "                    g_d2 -= (v/D2)**2\n",
    "                g = g_d1*D1/D + g_d2*D2/D\n",
    "                if g < m1:\n",
    "                    m1 = g\n",
    "                    Xa_value = split[index]\n",
    "                # elif m1 < g < m2:\n",
    "                    # m2 = g\n",
    "            return [m1, Xa_value]\n",
    "\n",
    "        else:  # discrete feature_values\n",
    "            length = len(njk)\n",
    "            if length > 10:  # too many discrete feature values, estimate\n",
    "                for j, k in njk.items():\n",
    "                    D1 = sum(k.values())\n",
    "                    D2 = D - D1\n",
    "                    g_d1 = 1\n",
    "                    g_d2 = 1\n",
    "\n",
    "                    D2_class_frequency = {}\n",
    "                    for key, value in class_frequency.items():\n",
    "                        if key in k:\n",
    "                            D2_class_frequency[key] = value - k[key]\n",
    "                        else:\n",
    "                            D2_class_frequency[key] = value\n",
    "                    for key, v in k.items():\n",
    "                        g_d1 -= (v/D1)**2\n",
    "\n",
    "                    if D2 != 0:\n",
    "                        for key, v in D2_class_frequency.items():\n",
    "                            g_d2 -= (v/D2)**2\n",
    "                    g = g_d1*D1/D + g_d2*D2/D\n",
    "                    if g < m1:\n",
    "                        m1 = g\n",
    "                        Xa_value = j\n",
    "                    # elif m1 < g < m2:\n",
    "                        # m2 = g\n",
    "                right = list(np.setdiff1d(feature_values, Xa_value))\n",
    "\n",
    "            else:  # fewer discrete feature values, get combinations\n",
    "                comb = self.select_combinations(feature_values)\n",
    "                for i in comb:\n",
    "                    left = list(i)\n",
    "                    D1_class_frequency = {key: 0 for key in class_frequency.keys()}\n",
    "                    D2_class_frequency = {key: 0 for key in class_frequency.keys()}\n",
    "                    for j,k in njk.items():\n",
    "                        for key, value in class_frequency.items():\n",
    "                            if j in left:\n",
    "                                if key in k:\n",
    "                                    D1_class_frequency[key] += k[key]\n",
    "                            else:\n",
    "                                if key in k:\n",
    "                                    D2_class_frequency[key] += k[key]\n",
    "                    g_d1 = 1\n",
    "                    g_d2 = 1\n",
    "                    D1 = sum(D1_class_frequency.values())\n",
    "                    D2 = D - D1\n",
    "                    for key, v in D1_class_frequency.items():\n",
    "                        g_d1 -= (v/D1)**2\n",
    "                    for key, v in D2_class_frequency.items():\n",
    "                        g_d2 -= (v/D2)**2\n",
    "                    g = g_d1*D1/D + g_d2*D2/D\n",
    "                    if g < m1:\n",
    "                        m1 = g\n",
    "                        Xa_value = left\n",
    "                    # elif m1 < g < m2:\n",
    "                        # m2 = g\n",
    "                right = list(np.setdiff1d(feature_values, Xa_value))\n",
    "            return [m1, [Xa_value, right]]\n",
    "\n",
    "    # divide values into two groups, return the combination of left groups\n",
    "    def select_combinations(self, feature_values):\n",
    "        combination = []\n",
    "        e = len(feature_values)\n",
    "        if e % 2 == 0:\n",
    "            end = int(e/2)\n",
    "            for i in range(1, end+1):\n",
    "                if i == end:\n",
    "                    cmb = list(combinations(feature_values, i))\n",
    "                    enough = int(len(cmb)/2)\n",
    "                    combination.extend(cmb[:enough])\n",
    "                else:\n",
    "                    combination.extend(combinations(feature_values, i))\n",
    "        else:\n",
    "            end = int((e-1)/2)\n",
    "            for i in range(1, end+1):\n",
    "                combination.extend(combinations(feature_values, i))\n",
    "\n",
    "        return combination\n",
    "\n",
    "\n",
    "# very fast decision tree class, i.e. hoeffding tree\n",
    "class Vfdt:\n",
    "    def __init__(self, features, delta=0.01, nmin=100, tau=0.1):\n",
    "        \"\"\"\n",
    "        :features: list of data features\n",
    "        :delta: used to compute hoeffding bound, error rate\n",
    "        :nmin: to limit the G computations\n",
    "        :tau: to deal with ties\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.delta = delta\n",
    "        self.nmin = nmin\n",
    "        self.tau = tau\n",
    "        self.root = VfdtNode(features)\n",
    "        self.n_examples_processed = 0\n",
    "\n",
    "    # update the tree by adding training example\n",
    "    def update(self, x, y):\n",
    "        self.n_examples_processed += 1\n",
    "        node = self.root.sort_example(x)\n",
    "        node.update_stats(x, y)\n",
    "\n",
    "        result = node.attempt_split(self.delta, self.nmin, self.tau)\n",
    "        if result is not None:\n",
    "            feature = result[0]\n",
    "            value = result[1]\n",
    "            self.node_split(node, feature, value)\n",
    "\n",
    "    # split node, produce children\n",
    "    def node_split(self, node, split_feature, split_value):\n",
    "        features = node.possible_split_features\n",
    "        # print('node_split')\n",
    "        left = VfdtNode(features)\n",
    "        right = VfdtNode(features)\n",
    "        node.add_children(split_feature, split_value, left, right)\n",
    "\n",
    "    # predict test example's classification\n",
    "    def predict(self, x_test):\n",
    "        prediction = []\n",
    "        if isinstance(x_test, np.ndarray) or isinstance(x_test, list):\n",
    "            for x in x_test:\n",
    "                leaf = self.root.sort_example(x)\n",
    "                prediction.append(leaf.most_frequent())\n",
    "            return prediction\n",
    "        else:\n",
    "            leaf = self.root.sort_example(x_test)\n",
    "            return leaf.most_frequent()\n",
    "\n",
    "    def print_tree(self, node):\n",
    "        if node.is_leaf():\n",
    "            print('Leaf')\n",
    "        else:\n",
    "            print(node.split_feature)\n",
    "            self.print_tree(node.left_child)\n",
    "            self.print_tree(node.right_child)\n",
    "\n",
    "\n",
    "def calc_metrics(y_test, y_pred, row_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    metrics = list(precision_recall_fscore_support(y_test, y_pred, average='weighted',\n",
    "                                                   labels=np.unique(y_pred)))\n",
    "    metrics = pd.DataFrame({'accuracy': accuracy, 'precision': metrics[0],'recall': metrics[1],\n",
    "                            'f1': metrics[2]}, index=[row_name])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test_run():\n",
    "    start_time = time.time()\n",
    "\n",
    "    df = pd.read_csv('./training_1001_labeled.csv', header=None, sep=',', skiprows=1)\n",
    "    df_test = pd.read_csv('./testing_1001_video.csv',header=None,sep=',', skiprows=1)\n",
    "    # df = pd.read_csv('./dataset/default_of_credit_card_clients.csv', skiprows=1, header=0)\n",
    "    \n",
    "    #df = df.drop(df.columns[0], axis=1)\n",
    "    \n",
    "    #df = df.sample(frac=1).reset_index(drop=True)  # shuffle data rows\n",
    "    title = list(df.columns.values)\n",
    "    features = title[:-1]\n",
    "    features = [0,1,2,3,4,5,6]\n",
    "    rows = df.shape[0]\n",
    "\n",
    "\n",
    "    #n_training = int(df.shape[0] * 0.4)\n",
    "    #training_data = df.iloc[:n_training]\n",
    "    #n_cache = int(df.shape[0] * 0.6)\n",
    "    #n_training = n_training - n_cache\n",
    "    \n",
    "    # date head\n",
    "    array = df.head(df.shape[0]).values\n",
    "    array = np.delete(array,1, axis=1)\n",
    "    x_train__ = array[:,:-1]\n",
    "    y_train__ = array[:,-1]\n",
    "    set1 = array[:int(df.shape[0] / 3), :]\n",
    "    set2 = array[int(df.shape[0] / 3):int(df.shape[0] / 3 * 2), :]\n",
    "    set3 = array[int(df.shape[0] / 3 * 2):, :]\n",
    "    \n",
    "    # cache head\n",
    "    #cache_boxes = df.tail(n_cache).values\n",
    "    #cache_boxes = np.delete(cache_boxes,1, axis=1)\n",
    "    #x_cache = cache_boxes[:,:-1]\n",
    "    #y_cache = cache_boxes[:,-1]\n",
    "\n",
    "    # to simulate continuous training, modify the tree for each training set\n",
    "    examples = [set1, set2, set3]\n",
    "\n",
    "    # test set is different from training set\n",
    "    #n_test = int(df.shape[0] * 0.3)\n",
    "    #test_set = df.tail(n_test).values\n",
    "    #x_test = test_set[:, :-1]\n",
    "    #y_test = test_set[:, -1]\n",
    "\n",
    "    # Heoffding bound (epsilon) parameter delta: with 1 - delta probability\n",
    "    # the true mean is at least r_bar - epsilon\n",
    "    # Efdt parameter nmin: test split if new sample size > nmin\n",
    "    # feature_values: unique values in every feature\n",
    "    # tie breaking: when difference is so small, split when diff_g < epsilon < tau\n",
    "\n",
    "    tree = Vfdt(features, delta=0.01, nmin=100, tau=0.5)\n",
    "\n",
    "    print('Total data size: ', rows)\n",
    "    #print('Training size: ', n_training)\n",
    "    #print('Cache set size: ', n_cache)\n",
    "    n = 0\n",
    "    \n",
    "    \n",
    "    for training_set in examples:\n",
    "        n += len(training_set)\n",
    "        x_train = training_set[:, :-1]\n",
    "        y_train = training_set[:, -1]\n",
    "        for x, y in zip(x_train, y_train):\n",
    "            tree.update(x, y)  # fit data\n",
    "        y_pred = tree.predict(x_train__)\n",
    "        y_array = np.array(y_pred)\n",
    "        idx = np.where(y_array == 4)[0]\n",
    "        idx_1 = np.where(y_array == 3)[0]\n",
    "        print('Training set:', n, end=', ')\n",
    "        print(y_train__.shape)\n",
    "        print(len(y_pred))\n",
    "        print('ACCURACY: %.4f' % accuracy_score(y_train__, y_pred))\n",
    "    #df_test = pd.read_csv('./testing_1001_video.csv', header=None)\n",
    "    df_video = pd.read_csv('./training_1001_video.csv', header=None)\n",
    "    total_size = df_test.shape[0]\n",
    "    \n",
    "    #df_video = df_video.tail(n_cache).values\n",
    "    order = [4,3,2,1,0]\n",
    "    #cach size range {500,5000,50000}\n",
    "    for length in range(100,100+1,500):\n",
    "        cache_cotainer = []\n",
    "        hit = 0\n",
    "        while(len(cache_cotainer) < length):\n",
    "            for i in range(0,4+1):\n",
    "                idx = np.where(y_array == order[i])[0]\n",
    "                for ii in idx:\n",
    "                    if len(cache_cotainer) < length:\n",
    "                        cache_cotainer.append(df_video.iloc[ii,0])\n",
    "                    else:\n",
    "                        break\n",
    "        for item in df_test.iloc[:,0]:\n",
    "            if item in cache_cotainer:\n",
    "                hit += 1\n",
    "        print(\"Cach Size %5f ---Hit Rate: %f\" % (length,hit/total_size*100))\n",
    "        \n",
    "        \n",
    "            \n",
    "    # tree.print_tree(tree.root)\n",
    "    print(\"--- Running time: %.6f seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size:  57350\n",
      "Training set: 19116, (57350,)\n",
      "57350\n",
      "ACCURACY: 0.9976\n",
      "Training set: 38233, (57350,)\n",
      "57350\n",
      "ACCURACY: 0.9994\n",
      "Training set: 57350, (57350,)\n",
      "57350\n",
      "ACCURACY: 0.9995\n",
      "Cach Size 100.000000 ---Hit Rate: 0.704863\n",
      "--- Running time: 2.939139 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wmnet\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2827: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Total data size:  90003\n",
      "Training size:  36001\n",
      "Test set size:  54001\n",
      "Training set: 12000, ACCURACY: 0.5247\n",
      "Training set: 24000, ACCURACY: 0.5524\n",
      "Training set: 36001, ACCURACY: 0.5639\n",
      "--- Running time: 5.666027 seconds ---\n"
     ]
    }
   ],
   "source": [
    "test_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
